{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "842d65c3-1115-445b-9989-6aec736b5902",
   "metadata": {},
   "source": [
    "##### This notebook helps to gather meta-data of research papers from five information scources, including ACM, Scopus, Springer, IEEE Xplore, and Scholar. For this to work you need to recieve api keys from Scopus, Springer, and IEEE Xplore and replace them in the code. Also, you need to change the search phrase in accordance with your needs. Note that since Scholar, bans the access at some point, it may take some hours to gather its data. It also, lets you to combine different results and merge repeating records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd812645-0fe1-4ba8-9635-9587afc6a47b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "import datetime\n",
    "html_doc = requests.get('https://dl.acm.org/action/doSearch?AllField=%28%22time+series%22+OR+%22time-series%22%29+AND+%22anomaly+detection%22%29&startPage=0&pageSize=50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d86ba13e-4fa8-4e6d-a51f-60f32841c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = datetime.datetime.now().date().strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812858a2-7560-461d-80c6-9547d164228a",
   "metadata": {},
   "source": [
    "# ACM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73ae6f30-8959-499e-8f20-e98a65eb4270",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html_doc.text, 'html.parser')\n",
    "paper_count = soup.find_all('span', attrs={'class':'hitsLength'})\n",
    "paper_count = int(paper_count[0].text.replace(',', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc3bf4e-b1a2-40a6-950d-0c3ef0f1018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_doi_year(html_doc):\n",
    "     time.sleep(np.random.randint(5))\n",
    "     soup = BeautifulSoup(html_doc.text, 'html.parser')\n",
    "     tit_class = \"hlFld-Title\"\n",
    "     s = soup.find_all('span', attrs={'class': re.compile(r'hlFld-Title|hlFld-ContentGroupTitle')})\n",
    "     bdois = [x.find('a').attrs['href'] for x in s]\n",
    "     btitles = [x.text for x in s]\n",
    "     c = 'dot-separator'\n",
    "     soup = BeautifulSoup(html_doc.text, 'html.parser')\n",
    "     s = soup.find_all('div', attrs={'class': 'issue-item__citation'})\n",
    "     byears = [re.findall('([2019]{2}\\d{2})', x.text)[0] for x in s]\n",
    "     return btitles, bdois, byears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb10e73-f4e2-46bb-8775-76a708ac19e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c4b0cdda2542b1bbe00fff6b8d0073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ps = int(paper_count/50)\n",
    "titles, dois, years = [],[], []\n",
    "for p in tqdm(range(0, ps+2)):\n",
    "     html_doc = requests.get(f'https://dl.acm.org/action/doSearch?AllField=%28%22time+series%22+OR+%22time-series%22%29+AND+%22anomaly+detection%22%29&startPage={p}&pageSize=50')\n",
    "     ttitles, tdois, tyears = title_doi_year(html_doc)\n",
    "     titles.extend(ttitles)\n",
    "     dois.extend(tdois)\n",
    "     if len(ttitles) != len(tyears):\n",
    "        print(p, len(ttitles), len(tyears))\n",
    "        break\n",
    "     years.extend(tyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b284358-e47a-4efe-9117-cd0693d53a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(({'title': titles, 'doi': dois, 'year': years}))\n",
    "df.to_excel(f'raw_output/acm - {d}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8172aee6-8c1a-44a4-9548-104d20503d8d",
   "metadata": {},
   "source": [
    "# Scopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b4e098-f016-41d5-8770-0d27210efeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.elsevier.com/content/search/scopus?query=TITLE-ABS-KEY((%7Btime-series%7D%20OR%20%7Btime%20series%7D)%20AND%20%7Banomaly%20detection%7D)&apiKey=ce09555ff6bb6918ae44f5c2d0bfa3d6&start=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639585b3-92df-4406-80b8-82d51cc0faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "res = requests.get(url)\n",
    "y = json.loads(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e140cdb5-323d-47a0-aa38-98471f311726",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = int(int(y['search-results']['opensearch:totalResults'])/25)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72554345-3cb5-4635-a703-ecbce6c847f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titles, dois, years = [], [], []\n",
    "for p in tqdm(range(0, ps)):\n",
    "     html_doc = requests.get(f'https://api.elsevier.com/content/search/scopus?query=TITLE-ABS-KEY((%7Btime-series%7D%20OR%20%7Btime%20series%7D)%20AND%20%7Banomaly%20detection%7D)&start={p*25}&apiKey=ce09555ff6bb6918ae44f5c2d0bfa3d6')\n",
    "     y = json.loads(html_doc.text)\n",
    "     ttitles = [x['dc:title'] for x in y['search-results']['entry']]\n",
    "     tdois = [x.get('prism:doi') for x in y['search-results']['entry']]\n",
    "     tyears = [x.get('prism:coverDate')[:4] for x in y['search-results']['entry']]\n",
    "     titles.extend(ttitles)\n",
    "     dois.extend(tdois)\n",
    "     years.extend(tyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3646bf-a96c-4bab-be9d-82f6b42779aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(({'title': titles, 'doi': dois, 'year': years}))\n",
    "df.to_excel(f'raw_output/scopus - {d}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce88c07-ad36-4a80-9bf4-7b9820e4d1da",
   "metadata": {},
   "source": [
    "# Springer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c31df5a8-ffe1-456e-877d-237627d71349",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = requests.get('http://api.springernature.com/metadata/json?q=(%22anomaly%20detection%22%20AND%20(%22time%20series%22%20OR%20%22time-series%22))&api_key=c74deaf5b45b6c8c99fdb3cdba6636c8&p=50&s=1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41552dc-a783-42c3-bfbb-b4c479e3df4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_recs = int(json.loads(data)['result'][0]['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc4bb1-a7b2-4405-b46d-e81285c3f7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c = int(total_recs/50)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9c9b35-409b-4dc2-ae25-74354a4659cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titles, dois, years = [], [], []\n",
    "from tqdm.notebook import tqdm\n",
    "for i in tqdm(range(c)):\n",
    "    start = (i*50)+1\n",
    "    url = f'http://api.springernature.com/metadata/json?q=(%22anomaly%20detection%22%20AND%20(%22time%20series%22%20OR%20%22time-series%22))&api_key=c74deaf5b45b6c8c99fdb3cdba6636c8&p=50&s={start}'\n",
    "    data = requests.get(url).text\n",
    "    ttitles = [x['title'] for x in json.loads(data)['records']]\n",
    "    tdois = [x['doi'] for x in json.loads(data)['records']]\n",
    "    tyears = [int(x['publicationDate'][:4]) for x in json.loads(data)['records']]\n",
    "    titles.extend(ttitles)\n",
    "    dois.extend(tdois)\n",
    "    years.extend(tyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bfe39f-b7c0-4777-9e4f-ea5d1c58c415",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(({'title': titles, 'doi': dois, 'year': years}))\n",
    "df.to_excel(f'raw_output/springer - {d}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049e573c-9f6b-4241-8eba-cc3fefe6861b",
   "metadata": {},
   "source": [
    "# IEEE Xplore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515741ba-c545-4d40-b722-a4a777cbffd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "page = requests.get('https://ieeexploreapi.ieee.org/api/v1/search/articles?parameter&apikey=vfcz6t7cawnewumrf7yp2gyd&querytext=(%22anomaly%20detection%22%20and%20(%22time%20series%22%20or%20%22time-series%22))&start_record=24&max_records=200')\n",
    "j = json.loads(page.text)\n",
    "totals = j['total_records']\n",
    "c = int(totals/200)+1\n",
    "titles, dois, years, abss = [], [], [], []\n",
    "for i in tqdm(range(c)):\n",
    "    page = requests.get(f'https://ieeexploreapi.ieee.org/api/v1/search/articles?parameter&apikey=vfcz6t7cawnewumrf7yp2gyd&querytext=(%22anomaly%20detection%22%20and%20(%22time%20series%22%20or%20%22time-series%22))&start_record={i*200}&max_records=200')\n",
    "    j = json.loads(page.text)\n",
    "    titles.extend([x['title'] for x in j[\"articles\"]])\n",
    "    dois.extend([x.get('doi', '') for x in j[\"articles\"]])\n",
    "    years.extend([x['publication_year'] for x in j[\"articles\"]])\n",
    "    abss.extend([x['abstract'] for x in j[\"articles\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5317e9-8545-4496-ba68-46f55337d0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(({'title': titles, 'doi': dois, 'year': years, 'abstract': abss}))\n",
    "df.to_excel(f'raw_output/ieee xplore - {d}.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679247a1-9da8-46e6-b139-cf980963ba5f",
   "metadata": {},
   "source": [
    "# Scholar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4de8b55b-0309-471d-955e-bd438413ca80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat(xtext):\n",
    "    try:\n",
    "        return re.findall('\\xa0- (.*), ', xtext)[0]\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "babdbddd-6f0e-4812-a654-551ceb19c44a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "\n",
    "data = requests.get('https://scholar.google.com/scholar?q=%22anomaly+detection%22+AND+(%22time-series%22+OR+%22time+series%22)')\n",
    "soup = BeautifulSoup(data.text, 'html.parser')\n",
    "ttitles = soup.find_all('h3', attrs={'class':'gs_rt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "667dc59f-5e02-4015-9fc4-04b8bc16cc1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed6fa9e18c44eb3a6504a8255b97af3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n",
      "Robot, I have to hide!\n"
     ]
    }
   ],
   "source": [
    "titles, years, journals = [], [], []\n",
    "for i in tqdm(range(100)):\n",
    "    t = np.random.randint(20)\n",
    "    if soup.find_all('form', attrs={'id':'captcha-form'}):\n",
    "        print('Robot, I have to hide!')\n",
    "        time.sleep(60*60*4)\n",
    "    time.sleep(t)\n",
    "    s = i*10\n",
    "    data = requests.get(f'https://scholar.google.com/scholar?q=%22anomaly+detection%22+AND+(%22time-series%22+OR+%22time+series%22)&hl=en&start={i*10}&as_sdt=0,5&as_vis=1')\n",
    "    soup = BeautifulSoup(data.text, 'html.parser')\n",
    "    ttitles = soup.find_all('h3', attrs={'class':'gs_rt'})\n",
    "    ttitles = [x.text for x in ttitles]\n",
    "    gs = soup.find_all('div', attrs={'class':'gs_a'})\n",
    "    tyears = [re.findall('[,-] ([1920]{2}\\d{2})', x.text)[0] for x in gs]\n",
    "    tjournals = [cat(x.text) for x in gs]\n",
    "    titles.extend(ttitles)\n",
    "    years.extend(tyears)\n",
    "    journals.extend(tjournals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b86a1e7-fc41-4c5a-8820-fc57b448d65a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-b189f0bcdd75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtitles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'year'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0myears\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'journal'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mjournals\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'raw_output/scholar - {d}.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[1;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 636\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    637\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[1;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# figure out the index, if necessary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    672\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    673\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 674\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"All arrays must be of the same length\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    676\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(({'title': titles, 'year': years, 'journal': journals}))\n",
    "df.to_excel(f'raw_output/scholar - {d}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "161fa187-26bd-45c5-80c4-6d9653ebdde5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(journals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54ddd5-6fb2-4ed1-b59c-06aa9ff40544",
   "metadata": {},
   "source": [
    "# Merging results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798d134-e15a-4383-b6bb-1fee282ab8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "acm = pd.read_excel(f'raw_output/acm.xlsx', index_col = None)\n",
    "ieee = pd.read_excel(f'raw_output/ieee xplore - {d}.xlsx')\n",
    "scopus = pd.read_excel(f'raw_output/scopus - {d}.xlsx')\n",
    "springer = pd.read_excel(f'raw_output/springer - {d}.xlsx')\n",
    "acm['doi'] = acm['doi'].str[5:]\n",
    "df = acm.append(ieee).append(scopus).append(springer)\n",
    "df_doi = df.drop_duplicates('doi')\n",
    "df_doi['title_'] = df_doi['title'].str.replace(' ', '').str.lower().str.replace('\\n', '')\n",
    "df_doi_title = df_doi.drop_duplicates('title_').sort_values('title_')\n",
    "df_doi = df.drop_duplicates('doi')\n",
    "df_doi['title_'] = df_doi['title'].str.replace(' ', '').str.lower().str.replace('\\n', '')\n",
    "df_doi_title = df_doi.drop_duplicates('title_').sort_values('title_')\n",
    "df_doi_title[df_doi_title['year']>2017]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1d117a-6383-4e56-87d1-101c6b811cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "ss.entropy([2,2]), ss.entropy([1,1,1]), ss.entropy([1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02608618-dda9-4515-ad25-1515eee42731",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "l = []\n",
    "for i in range(1,10000):\n",
    "    s.append(ss.entropy([1]*i))\n",
    "    l.append(np.log(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db1d28-6ea7-4c5f-a168-0a74b49ef758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(s)\n",
    "plt.plot(l)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
